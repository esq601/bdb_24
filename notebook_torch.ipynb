{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(week):\n",
    "    # Reading the CSV files\n",
    "    week1 = pd.read_csv(f\"tracking_week_{week}.csv\", dtype={\"nflId\": str, \"playId\": str})\n",
    "    plays = pd.read_csv(\"plays.csv\", dtype={\"playId\": str})\n",
    "    tackles = pd.read_csv(\"tackles.csv\", dtype={\"nflId\": str, \"playId\": str})\n",
    "\n",
    "    # Transforming the tackles dataframe\n",
    "    tackles[\"t_val\"] = np.where(tackles[\"tackle\"] == 1, 1,\n",
    "                                np.where(tackles[\"assist\"] == 1, 0.5, 0))\n",
    "    tackles[\"event\"] = \"tackle\"\n",
    "    tackle_title = tackles[[\"gameId\", \"playId\", \"nflId\", \"event\", \"t_val\"]]\n",
    "\n",
    "    # Extracting the football data\n",
    "    football = week1[week1[\"displayName\"] == \"football\"]\n",
    "    football = football[[\"gameId\", \"playId\", \"frameId\", \"x\", \"y\", \"s\", \"a\"]]\n",
    "    football[\"playId\"] = football[\"gameId\"].astype(str) + \"_\" + football[\"playId\"]\n",
    "\n",
    "    # Extracting possession team data\n",
    "    poss_tm = plays[[\"gameId\", \"playId\", \"possessionTeam\"]]\n",
    "    poss_tm[\"playId\"] = poss_tm[\"gameId\"].astype(str) + \"_\" + poss_tm[\"playId\"]\n",
    "\n",
    "    # Start building the main dataframe df\n",
    "    df = week1[week1[\"displayName\"] != \"football\"]\n",
    "    df[\"playId\"] = df[\"gameId\"].astype(str) + \"_\" + df[\"playId\"]\n",
    "\n",
    "    # Merging football data with df using left join\n",
    "    df = df.merge(football, on=[\"playId\", \"frameId\"], how=\"left\", suffixes=(\"_p\", \"_f\"))\n",
    "\n",
    "    df = df.merge(poss_tm, on=[\"playId\"], how=\"left\")\n",
    "    df[\"poss_tm\"] = np.where(df[\"club\"] == df[\"possessionTeam\"], 1, 0)\n",
    "    df = df.merge(tackle_title, on=[\"gameId\", \"playId\", \"nflId\", \"event\"], how=\"left\")\n",
    "    df[\"t_val\"].fillna(0, inplace=True)\n",
    "    df[\"ball_dist\"] = np.sqrt((df[\"x_f\"] - df[\"x_p\"])**2 + (df[\"y_f\"] - df[\"y_p\"])**2)\n",
    "    df = df[[\"playId\", \"nflId\", \"frameId\", \"s_p\", \"a_p\", \"s_f\", \"a_f\", \"ball_dist\", \"poss_tm\", \"t_val\"]]\n",
    "\n",
    "    # Sorting by playId, nflId, and frameId\n",
    "    # df = df.sort_values(by=[\"playId\", \"nflId\", \"frameId\"])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esq60\\AppData\\Local\\Temp/ipykernel_8216/2557294830.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poss_tm[\"playId\"] = poss_tm[\"gameId\"].astype(str) + \"_\" + poss_tm[\"playId\"]\n",
      "C:\\Users\\esq60\\AppData\\Local\\Temp/ipykernel_8216/2557294830.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"playId\"] = df[\"gameId\"].astype(str) + \"_\" + df[\"playId\"]\n"
     ]
    }
   ],
   "source": [
    "df = gen_data('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                   playId  nflId  frameId   s_p   a_p        s_f        a_f  \\\n",
       "0          2022090800_56  35472        1  1.62  1.15  22.209999  11.850000   \n",
       "1          2022090800_56  35472        2  1.67  0.61  20.900000  13.820000   \n",
       "2          2022090800_56  35472        3  1.57  0.49  19.000000  16.020000   \n",
       "3          2022090800_56  35472        4  1.44  0.89  17.280001  15.400000   \n",
       "4          2022090800_56  35472        5  1.29  1.24  13.360000  20.459999   \n",
       "...                  ...    ...      ...   ...   ...        ...        ...   \n",
       "1346241  2022091200_3826  54618       49  1.88  2.49   2.560000   1.250000   \n",
       "1346242  2022091200_3826  54618       50  1.84  2.35   2.500000   1.140000   \n",
       "1346243  2022091200_3826  54618       51  1.85  1.98   2.380000   1.700000   \n",
       "1346244  2022091200_3826  54618       52  1.85  1.69   2.070000   2.830000   \n",
       "1346245  2022091200_3826  54618       53  1.80  1.37   1.860000   3.000000   \n",
       "\n",
       "         ball_dist  poss_tm  t_val  \n",
       "0         7.334439        1    0.0  \n",
       "1         9.359082        1    0.0  \n",
       "2        10.960330        1    0.0  \n",
       "3        12.784855        1    0.0  \n",
       "4        13.839862        1    0.0  \n",
       "...            ...      ...    ...  \n",
       "1346241   6.224292        0    0.0  \n",
       "1346242   5.995616        0    0.0  \n",
       "1346243   5.760946        0    0.0  \n",
       "1346244   5.542923        0    0.0  \n",
       "1346245   5.316013        0    0.0  \n",
       "\n",
       "[1346246 rows x 10 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume df is the dataframe from gen_data\n",
    "features = ['s_p', 'a_p', 's_f', 'a_f', 'ball_dist', 'poss_tm']\n",
    "scaler = StandardScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_sequences(df, sequence_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    play_ids = df['playId'].unique()\n",
    "    \n",
    "    for play_id in play_ids:\n",
    "        play_data = df[df['playId'] == play_id].sort_values(by='frameId')\n",
    "        \n",
    "        for i in range(0, play_data.shape[0] - sequence_length):\n",
    "            sequences.append(play_data[features].iloc[i:i+sequence_length].values)\n",
    "            targets.append(play_data['t_val'].iloc[i+sequence_length-1])\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "sequence_length = 10\n",
    "X, y = transform_to_sequences(df, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Take the output from the last time step\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train[:, None], dtype=torch.float32)  # Adding an extra dimension for BCE loss\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val[:, None], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(features)\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, dropout)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train_tensor[i:i+batch_size]\n",
    "        y_batch = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Validation loss\n",
    "    val_outputs = model(X_val_tensor)\n",
    "    val_loss = criterion(val_outputs, y_val_tensor)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Val Loss: {val_loss.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('datasci')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c57d0803981c1b0f0052a3f88c1a7e16b7e2e9e67b7445bebf0bfb810371e677"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
